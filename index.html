<!-- HTML untuk Hand Tracker -->
<video id="input_video"></video>
<canvas id="output_canvas"></canvas>

<div id="buttons">
  <a href="https://tiktokrobotikaterbaik.netlify.app/" target="_blank" class="portfolioBtn">üåê Buka Portofolio</a>
</div>

<div id="status">Arahkan jari telunjuk ke tombol.</div>

<!-- Mediapipe -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<script>
  const videoElement = document.getElementById("input_video");
  const canvasElement = document.getElementById("output_canvas");
  const canvasCtx = canvasElement.getContext("2d");
  const uiDiv = document.getElementById("status");

  canvasElement.width = window.innerWidth;
  canvasElement.height = window.innerHeight;

  const clickableEls = document.querySelectorAll('a, button, .portfolioBtn');

  /* ---------------------------
      TTS (Text to Speech)
  ----------------------------*/
  let hasSpoken = false;
  function speakIntro(){
    if(hasSpoken) return; // biar tidak ulang-ulang
    hasSpoken = true;

    const msg = new SpeechSynthesisUtterance("Hallo, nama saya Arby");
    msg.lang = "id-ID";
    msg.rate = 1;  
    msg.pitch = 1; 
    speechSynthesis.speak(msg);
  }

  let lastClickTime = 0;
  function checkFingerClick(fx, fy){
    const now = Date.now();
    if(now - lastClickTime < 800) return;
    clickableEls.forEach((el)=>{
      const rect = el.getBoundingClientRect();
      if(fx > rect.left && fx < rect.right && fy > rect.top && fy < rect.bottom){
        uiDiv.textContent = `Klik Virtual: ${el.textContent || el.href}`;
        el.classList.add('active');
        setTimeout(()=>el.classList.remove('active'),300);
        el.click();
        lastClickTime = now;
      }
    });
  }

  let lastScroll = Date.now();
  function autoScroll(fy){
    const now = Date.now();
    if(now - lastScroll < 300) return;
    if(fy < window.innerHeight * 0.2){
      window.scrollBy({top:-150,behavior:'smooth'});
      uiDiv.textContent = "Scroll ‚Üë";
    } else if(fy > window.innerHeight * 0.8){
      window.scrollBy({top:150,behavior:'smooth'});
      uiDiv.textContent = "Scroll ‚Üì";
    }
    lastScroll = now;
  }

  function onResults(results){
    canvasCtx.save();
    canvasCtx.clearRect(0,0,canvasElement.width,canvasElement.height);
    canvasCtx.drawImage(results.image,0,0,canvasElement.width,canvasElement.height);

    if(results.multiHandLandmarks){
      // ‚ñ∂Ô∏è Suara muncul saat tangan terdeteksi pertama kali
      speakIntro();

      for(const landmarks of results.multiHandLandmarks){
        drawConnectors(canvasCtx,landmarks,HAND_CONNECTIONS,{color:'#00FF00',lineWidth:2});
        drawLandmarks(canvasCtx,landmarks,{color:'#FF0000',lineWidth:1});

        const indexFinger = landmarks[8];
        const fx = indexFinger.x * window.innerWidth;
        const fy = indexFinger.y * window.innerHeight;

        checkFingerClick(fx,fy);
        autoScroll(fy);
      }
    }

    canvasCtx.restore();
  }

  const hands = new Hands({
    locateFile:(file)=>`https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
  });
  hands.setOptions({
    maxNumHands:1,
    modelComplexity:1,
    minDetectionConfidence:0.7,
    minTrackingConfidence:0.7
  });
  hands.onResults(onResults);

  const camera = new Camera(videoElement,{
    onFrame:async()=>{
      await hands.send({image:videoElement});
    },
    width:640,
    height:480
  });
  camera.start();
</script>
